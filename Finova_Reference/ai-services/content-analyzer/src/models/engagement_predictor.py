"""
Finova Network - Content Engagement Predictor Model
Enterprise-grade AI model for predicting content engagement potential
Supports multi-platform social media content analysis with real-time scoring
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModel, pipeline
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import cv2
import librosa
import pickle
import json
import logging
from typing import Dict, List, Tuple, Optional, Union
from datetime import datetime, timedelta
import asyncio
import redis
from dataclasses import dataclass
import hashlib
import re
from urllib.parse import urlparse

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ContentFeatures:
    """Data class for content features"""
    text_features: Dict
    visual_features: Dict
    audio_features: Dict
    metadata_features: Dict
    platform_features: Dict
    temporal_features: Dict
    user_features: Dict

@dataclass
class EngagementPrediction:
    """Data class for engagement prediction results"""
    engagement_score: float
    confidence: float
    platform_specific_scores: Dict[str, float]
    viral_probability: float
    quality_multiplier: float
    xp_multiplier: float
    breakdown: Dict[str, float]
    recommendations: List[str]

class EngagementPredictor:
    """
    Advanced engagement prediction model for Finova Network
    Predicts content engagement potential across multiple social platforms
    """
    
    def __init__(self, config_path: str = None):
        """Initialize the engagement predictor"""
        self.config = self._load_config(config_path)
        self.models = {}
        self.scalers = {}
        self.encoders = {}
        self.tokenizer = None
        self.text_model = None
        self.redis_client = None
        self.feature_cache = {}
        
        # Platform-specific weights
        self.platform_weights = {
            'instagram': {'visual': 0.6, 'text': 0.2, 'hashtags': 0.15, 'timing': 0.05},
            'tiktok': {'visual': 0.5, 'audio': 0.3, 'text': 0.1, 'trends': 0.1},
            'youtube': {'visual': 0.4, 'audio': 0.3, 'text': 0.2, 'metadata': 0.1},
            'facebook': {'text': 0.4, 'visual': 0.3, 'social': 0.2, 'timing': 0.1},
            'twitter': {'text': 0.6, 'timing': 0.2, 'hashtags': 0.15, 'mentions': 0.05}
        }
        
        # Initialize components
        self._initialize_models()
        self._initialize_redis()
        
    def _load_config(self, config_path: str) -> Dict:
        """Load configuration from file or use defaults"""
        default_config = {
            'model_cache_ttl': 3600,
            'prediction_cache_ttl': 300,
            'max_text_length': 512,
            'image_size': (224, 224),
            'audio_sample_rate': 22050,
            'viral_threshold': 1000,
            'confidence_threshold': 0.7,
            'redis_host': 'localhost',
            'redis_port': 6379,
            'redis_db': 0
        }
        
        if config_path:
            try:
                with open(config_path, 'r') as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                logger.warning(f"Could not load config: {e}, using defaults")
                
        return default_config
    
    def _initialize_models(self):
        """Initialize all AI models"""
        try:
            # Text model for semantic analysis
            self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')
            self.text_model = AutoModel.from_pretrained('distilbert-base-uncased')
            
            # Sentiment analysis pipeline
            self.sentiment_analyzer = pipeline('sentiment-analysis', 
                                             model='cardiffnlp/twitter-roberta-base-sentiment-latest')
            
            # Initialize engagement prediction models
            self._load_pretrained_models()
            
            logger.info("All models initialized successfully")
            
        except Exception as e:
            logger.error(f"Model initialization failed: {e}")
            raise
    
    def _initialize_redis(self):
        """Initialize Redis connection for caching"""
        try:
            self.redis_client = redis.Redis(
                host=self.config['redis_host'],
                port=self.config['redis_port'],
                db=self.config['redis_db'],
                decode_responses=True
            )
            self.redis_client.ping()
            logger.info("Redis connection established")
        except Exception as e:
            logger.warning(f"Redis connection failed: {e}, using memory cache")
            self.redis_client = None
    
    def _load_pretrained_models(self):
        """Load or create pretrained engagement models"""
        # Main engagement prediction model
        self.models['engagement'] = self._create_engagement_model()
        
        # Platform-specific models
        for platform in self.platform_weights.keys():
            self.models[f'{platform}_engagement'] = self._create_platform_model(platform)
        
        # Viral prediction model
        self.models['viral'] = self._create_viral_model()
        
        # Quality assessment model
        self.models['quality'] = self._create_quality_model()
    
    def _create_engagement_model(self) -> nn.Module:
        """Create the main engagement prediction neural network"""
        return EngagementNN(
            input_dim=256,  # Combined feature dimension
            hidden_dims=[512, 256, 128, 64],
            output_dim=1,
            dropout=0.3
        )
    
    def _create_platform_model(self, platform: str) -> RandomForestRegressor:
        """Create platform-specific engagement model"""
        return RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
    
    def _create_viral_model(self) -> GradientBoostingRegressor:
        """Create viral content prediction model"""
        return GradientBoostingRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            random_state=42
        )
    
    def _create_quality_model(self) -> RandomForestRegressor:
        """Create content quality assessment model"""
        return RandomForestRegressor(
            n_estimators=50,
            max_depth=8,
            random_state=42
        )
    
    async def predict_engagement(self, 
                                content: Dict, 
                                user_profile: Dict = None,
                                platform: str = 'instagram') -> EngagementPrediction:
        """
        Main method to predict content engagement
        
        Args:
            content: Content data including text, images, video, audio
            user_profile: User profile data from Finova system
            platform: Target social media platform
            
        Returns:
            EngagementPrediction object with detailed results
        """
        try:
            # Generate cache key
            cache_key = self._generate_cache_key(content, user_profile, platform)
            
            # Check cache first
            cached_result = await self._get_cached_prediction(cache_key)
            if cached_result:
                return cached_result
            
            # Extract comprehensive features
            features = await self._extract_features(content, user_profile, platform)
            
            # Generate predictions
            engagement_score = self._predict_base_engagement(features)
            platform_scores = self._predict_platform_specific(features)
            viral_prob = self._predict_viral_probability(features)
            quality_mult = self._predict_quality_multiplier(features)
            xp_mult = self._calculate_xp_multiplier(engagement_score, quality_mult)
            
            # Create breakdown analysis
            breakdown = self._analyze_feature_importance(features)
            
            # Generate recommendations
            recommendations = self._generate_recommendations(features, breakdown)
            
            # Create prediction object
            prediction = EngagementPrediction(
                engagement_score=float(engagement_score),
                confidence=self._calculate_confidence(features),
                platform_specific_scores=platform_scores,
                viral_probability=float(viral_prob),
                quality_multiplier=float(quality_mult),
                xp_multiplier=float(xp_mult),
                breakdown=breakdown,
                recommendations=recommendations
            )
            
            # Cache the result
            await self._cache_prediction(cache_key, prediction)
            
            return prediction
            
        except Exception as e:
            logger.error(f"Engagement prediction failed: {e}")
            raise
    
    async def _extract_features(self, 
                               content: Dict, 
                               user_profile: Dict,
                               platform: str) -> ContentFeatures:
        """Extract comprehensive features from content and user data"""
        
        # Text features
        text_features = await self._extract_text_features(content.get('text', ''))
        
        # Visual features (images/video thumbnails)
        visual_features = await self._extract_visual_features(content.get('images', []))
        
        # Audio features (for video/audio content)
        audio_features = await self._extract_audio_features(content.get('audio_path'))
        
        # Metadata features
        metadata_features = self._extract_metadata_features(content)
        
        # Platform-specific features
        platform_features = self._extract_platform_features(content, platform)
        
        # Temporal features
        temporal_features = self._extract_temporal_features(content)
        
        # User features
        user_features = self._extract_user_features(user_profile)
        
        return ContentFeatures(
            text_features=text_features,
            visual_features=visual_features,
            audio_features=audio_features,
            metadata_features=metadata_features,
            platform_features=platform_features,
            temporal_features=temporal_features,
            user_features=user_features
        )
    
    async def _extract_text_features(self, text: str) -> Dict:
        """Extract comprehensive text features"""
        if not text:
            return {'length': 0, 'words': 0, 'sentiment': 0.0}
        
        # Basic statistics
        features = {
            'length': len(text),
            'word_count': len(text.split()),
            'sentence_count': len(re.split(r'[.!?]+', text)),
            'avg_word_length': np.mean([len(word) for word in text.split()]),
            'exclamation_count': text.count('!'),
            'question_count': text.count('?'),
            'hashtag_count': len(re.findall(r'#\w+', text)),
            'mention_count': len(re.findall(r'@\w+', text)),
            'emoji_count': len(re.findall(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', text)),
            'url_count': len(re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text))
        }
        
        # Sentiment analysis
        try:
            sentiment_result = self.sentiment_analyzer(text[:512])[0]
            features['sentiment_label'] = sentiment_result['label']
            features['sentiment_score'] = sentiment_result['score']
        except:
            features['sentiment_label'] = 'NEUTRAL'
            features['sentiment_score'] = 0.5
        
        # Semantic embeddings
        try:
            inputs = self.tokenizer(text[:512], return_tensors='pt', truncation=True, padding=True)
            with torch.no_grad():
                outputs = self.text_model(**inputs)
                embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
            features['semantic_embeddings'] = embeddings.tolist()[:50]  # Take first 50 dimensions
        except:
            features['semantic_embeddings'] = [0.0] * 50
        
        # Engagement keywords
        engagement_keywords = ['amazing', 'wow', 'incredible', 'love', 'awesome', 'fantastic', 'check out', 'must see']
        features['engagement_keywords'] = sum(1 for keyword in engagement_keywords if keyword.lower() in text.lower())
        
        # Reading complexity
        features['reading_complexity'] = self._calculate_reading_complexity(text)
        
        return features
    
    async def _extract_visual_features(self, images: List[str]) -> Dict:
        """Extract visual features from images"""
        if not images:
            return {'image_count': 0}
        
        features = {'image_count': len(images)}
        
        # Analyze first image (or thumbnail)
        if images:
            try:
                # Load and process image
                image_path = images[0]
                if image_path.startswith('http'):
                    # Download image logic here
                    pass
                else:
                    image = cv2.imread(image_path)
                    if image is not None:
                        # Basic image statistics
                        features.update({
                            'image_height': image.shape[0],
                            'image_width': image.shape[1],
                            'aspect_ratio': image.shape[1] / image.shape[0],
                            'brightness': np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)),
                            'contrast': np.std(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)),
                        })
                        
                        # Color analysis
                        features.update(self._analyze_image_colors(image))
                        
                        # Face detection
                        features['face_count'] = self._detect_faces(image)
                        
                        # Object detection
                        features.update(self._detect_objects(image))
            except Exception as e:
                logger.warning(f"Image analysis failed: {e}")
        
        return features
    
    async def _extract_audio_features(self, audio_path: str) -> Dict:
        """Extract audio features for video/audio content"""
        if not audio_path:
            return {'has_audio': False}
        
        features = {'has_audio': True}
        
        try:
            # Load audio
            y, sr = librosa.load(audio_path, duration=30)  # Analyze first 30 seconds
            
            # Basic audio features
            features.update({
                'duration': len(y) / sr,
                'tempo': librosa.beat.tempo(y=y, sr=sr)[0],
                'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),
                'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),
                'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(y)),
                'mfcc_mean': np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)),
                'energy': np.mean(y**2),
                'loudness': np.mean(librosa.amplitude_to_db(np.abs(librosa.stft(y))))
            })
            
            # Music/speech classification
            features['audio_type'] = self._classify_audio_type(y, sr)
            
        except Exception as e:
            logger.warning(f"Audio analysis failed: {e}")
            features.update({
                'duration': 0, 'tempo': 0, 'spectral_centroid': 0,
                'spectral_rolloff': 0, 'zero_crossing_rate': 0,
                'mfcc_mean': 0, 'energy': 0, 'loudness': 0,
                'audio_type': 'unknown'
            })
        
        return features
    
    def _extract_metadata_features(self, content: Dict) -> Dict:
        """Extract metadata features"""
        features = {
            'has_title': bool(content.get('title')),
            'title_length': len(content.get('title', '')),
            'has_description': bool(content.get('description')),
            'description_length': len(content.get('description', '')),
            'has_tags': bool(content.get('tags')),
            'tag_count': len(content.get('tags', [])),
            'content_type': content.get('type', 'post'),
            'is_original': content.get('is_original', True),
            'has_call_to_action': self._detect_call_to_action(content.get('text', '')),
            'content_category': content.get('category', 'general')
        }
        
        return features
    
    def _extract_platform_features(self, content: Dict, platform: str) -> Dict:
        """Extract platform-specific features"""
        features = {'platform': platform}
        
        if platform == 'instagram':
            features.update({
                'optimal_hashtag_count': min(30, len(re.findall(r'#\w+', content.get('text', '')))),
                'has_location': bool(content.get('location')),
                'is_story': content.get('content_type') == 'story',
                'is_reel': content.get('content_type') == 'reel'
            })
        elif platform == 'tiktok':
            features.update({
                'is_trending_sound': content.get('trending_sound', False),
                'video_length': content.get('duration', 0),
                'has_effects': bool(content.get('effects')),
                'challenge_participation': bool(content.get('challenge'))
            })
        elif platform == 'youtube':
            features.update({
                'video_length': content.get('duration', 0),
                'has_thumbnail': bool(content.get('thumbnail')),
                'category': content.get('category', 'entertainment'),
                'is_shorts': content.get('duration', 0) <= 60
            })
        elif platform == 'facebook':
            features.update({
                'post_type': content.get('post_type', 'status'),
                'has_link_preview': bool(content.get('link')),
                'is_event': content.get('content_type') == 'event',
                'target_audience': content.get('audience_size', 'public')
            })
        elif platform == 'twitter':
            features.update({
                'is_thread': content.get('is_thread', False),
                'reply_to': bool(content.get('reply_to')),
                'retweet_count': content.get('retweet_count', 0),
                'character_count': len(content.get('text', ''))
            })
        
        return features
    
    def _extract_temporal_features(self, content: Dict) -> Dict:
        """Extract temporal features"""
        now = datetime.now()
        
        features = {
            'hour_of_day': now.hour,
            'day_of_week': now.weekday(),
            'is_weekend': now.weekday() >= 5,
            'is_prime_time': 18 <= now.hour <= 22,
            'is_morning': 6 <= now.hour <= 10,
            'is_lunch_time': 11 <= now.hour <= 14,
            'month': now.month,
            'is_holiday_season': now.month in [11, 12, 1]
        }
        
        # Trending topics consideration
        features['trending_score'] = self._calculate_trending_score(content)
        
        return features
    
    def _extract_user_features(self, user_profile: Dict) -> Dict:
        """Extract user-specific features"""
        if not user_profile:
            return {'has_profile': False}
        
        features = {
            'has_profile': True,
            'follower_count': user_profile.get('follower_count', 0),
            'following_count': user_profile.get('following_count', 0),
            'post_count': user_profile.get('post_count', 0),
            'account_age_days': user_profile.get('account_age_days', 0),
            'verification_status': user_profile.get('is_verified', False),
            'avg_engagement_rate': user_profile.get('avg_engagement_rate', 0.0),
            'xp_level': user_profile.get('xp_level', 1),
            'rp_tier': user_profile.get('rp_tier', 0),
            'mining_rate': user_profile.get('current_mining_rate', 0.0),
            'quality_score_history': user_profile.get('avg_quality_score', 0.5),
            'content_consistency': user_profile.get('posting_consistency', 0.5),
            'audience_engagement': user_profile.get('audience_quality', 0.5)
        }
        
        # Calculate engagement ratio
        if features['follower_count'] > 0:
            features['engagement_ratio'] = features['avg_engagement_rate'] / features['follower_count']
        else:
            features['engagement_ratio'] = 0.0
        
        return features
    
    def _predict_base_engagement(self, features: ContentFeatures) -> float:
        """Predict base engagement score"""
        # Combine all features into a single vector
        feature_vector = self._combine_features(features)
        
        # Use the main engagement model
        with torch.no_grad():
            tensor_input = torch.FloatTensor(feature_vector).unsqueeze(0)
            engagement_score = self.models['engagement'](tensor_input).item()
        
        # Apply constraints (0.1 to 10.0 scale)
        return max(0.1, min(10.0, engagement_score))
    
    def _predict_platform_specific(self, features: ContentFeatures) -> Dict[str, float]:
        """Predict engagement for each platform"""
        platform_scores = {}
        feature_vector = self._combine_features(features)
        
        for platform in self.platform_weights.keys():
            try:
                # Apply platform-specific weighting
                weighted_features = self._apply_platform_weights(feature_vector, platform)
                score = self.models[f'{platform}_engagement'].predict([weighted_features])[0]
                platform_scores[platform] = max(0.1, min(10.0, score))
            except:
                platform_scores[platform] = 1.0
        
        return platform_scores
    
    def _predict_viral_probability(self, features: ContentFeatures) -> float:
        """Predict probability of content going viral"""
        feature_vector = self._combine_features(features)
        
        try:
            viral_score = self.models['viral'].predict([feature_vector])[0]
            return max(0.0, min(1.0, viral_score))
        except:
            return 0.1
    
    def _predict_quality_multiplier(self, features: ContentFeatures) -> float:
        """Predict content quality multiplier (0.5x to 2.0x)"""
        feature_vector = self._combine_features(features)
        
        try:
            quality_score = self.models['quality'].predict([feature_vector])[0]
            return max(0.5, min(2.0, quality_score))
        except:
            return 1.0
    
    def _calculate_xp_multiplier(self, engagement_score: float, quality_mult: float) -> float:
        """Calculate XP multiplier based on engagement and quality"""
        # Base XP multiplier formula from whitepaper
        base_multiplier = 1.0 + (engagement_score / 10.0)
        quality_bonus = (quality_mult - 1.0) * 0.5
        
        return min(5.0, base_multiplier + quality_bonus)
    
    def _combine_features(self, features: ContentFeatures) -> List[float]:
        """Combine all features into a single vector"""
        combined = []
        
        # Text features (50 dimensions)
        text_emb = features.text_features.get('semantic_embeddings', [0.0] * 50)
        combined.extend(text_emb[:50])
        
        # Numeric features
        numeric_features = [
            features.text_features.get('length', 0) / 1000.0,  # Normalize
            features.text_features.get('word_count', 0) / 100.0,
            features.text_features.get('sentiment_score', 0.5),
            features.text_features.get('engagement_keywords', 0) / 10.0,
            features.visual_features.get('image_count', 0) / 10.0,
            features.visual_features.get('brightness', 0) / 255.0,
            features.visual_features.get('contrast', 0) / 100.0,
            features.visual_features.get('face_count', 0) / 5.0,
            features.audio_features.get('duration', 0) / 300.0,  # 5 minutes max
            features.audio_features.get('energy', 0),
            features.temporal_features.get('trending_score', 0),
            features.user_features.get('xp_level', 1) / 100.0,
            features.user_features.get('rp_tier', 0) / 5.0,
            features.user_features.get('avg_engagement_rate', 0),
            features.user_features.get('quality_score_history', 0.5)
        ]
        
        combined.extend(numeric_features)
        
        # Categorical features (one-hot encoded)
        platform_encoding = [0.0] * len(self.platform_weights)
        platform = features.platform_features.get('platform', 'instagram')
        if platform in self.platform_weights:
            idx = list(self.platform_weights.keys()).index(platform)
            platform_encoding[idx] = 1.0
        combined.extend(platform_encoding)
        
        # Pad or truncate to fixed size
        target_size = 256
        if len(combined) < target_size:
            combined.extend([0.0] * (target_size - len(combined)))
        elif len(combined) > target_size:
            combined = combined[:target_size]
        
        return combined
    
    def _apply_platform_weights(self, features: List[float], platform: str) -> List[float]:
        """Apply platform-specific weights to features"""
        weights = self.platform_weights.get(platform, {})
        weighted_features = features.copy()
        
        # Apply weights based on feature importance for platform
        # This is a simplified implementation
        for i, weight in enumerate(weighted_features):
            if i < 50:  # Text features
                weighted_features[i] *= weights.get('text', 1.0)
            elif i < 100:  # Visual features
                weighted_features[i] *= weights.get('visual', 1.0)
            elif i < 150:  # Audio features
                weighted_features[i] *= weights.get('audio', 1.0)
        
        return weighted_features
    
    def _analyze_feature_importance(self, features: ContentFeatures) -> Dict[str, float]:
        """Analyze which features contribute most to engagement"""
        breakdown = {
            'text_contribution': 0.3,  # Simplified - would use SHAP in production
            'visual_contribution': 0.25,
            'audio_contribution': 0.15,
            'user_profile_contribution': 0.2,
            'timing_contribution': 0.1
        }
        
        # Adjust based on actual feature values
        if features.visual_features.get('image_count', 0) > 0:
            breakdown['visual_contribution'] += 0.1
            breakdown['text_contribution'] -= 0.05
        
        if features.audio_features.get('has_audio', False):
            breakdown['audio_contribution'] += 0.1
            breakdown['text_contribution'] -= 0.05
        
        if features.user_features.get('xp_level', 1) > 50:
            breakdown['user_profile_contribution'] += 0.1
        
        return breakdown
    
    def _generate_recommendations(self, features: ContentFeatures, breakdown: Dict) -> List[str]:
        """Generate actionable recommendations for improving engagement"""
        recommendations = []
        
        # Text recommendations
        text_features = features.text_features
        if text_features.get('length', 0) < 50:
            recommendations.append("Consider adding more descriptive text to increase engagement")
        
        if text_features.get('hashtag_count', 0) < 3:
            recommendations.append("Add 3-5 relevant hashtags to improve discoverability")
        
        if text_features.get('engagement_keywords', 0) == 0:
            recommendations.append("Include engaging words like 'amazing', 'incredible', or 'must-see'")
        
        # Visual recommendations
        visual_features = features.visual_features
        if visual_features.get('image_count', 0) == 0:
            recommendations.append("Add high-quality images to significantly boost engagement")
        
        if visual_features.get('brightness', 128) < 100:
            recommendations.append("Consider using brighter, more vibrant images")
        
        # Timing recommendations
        temporal_features = features.temporal_features
        if not temporal_features.get('is_prime_time', False):
            recommendations.append("Post during prime time (6-10 PM) for better engagement")
        
        # User profile recommendations
        user_features = features.user_features
        if user_features.get('quality_score_history', 0.5) < 0.7:
            recommendations.append("Focus on creating higher quality content to improve your multiplier")
        
        return recommendations[:5]  # Limit to top 5 recommendations
    
    def _calculate_confidence(self, features: ContentFeatures) -> float:
        """Calculate prediction confidence score"""
        confidence_factors = []
        
        # Text confidence
        if features.text_features.get('length', 0) > 0:
            confidence_factors.append(0.8)
        else:
            confidence_factors.append(0.3)
        
        # Visual confidence
        if features.visual_features.get('image_count', 0) > 0:
            confidence_factors.append(0.9)
        else:
            confidence_factors.append(0.5)
        
        # User profile confidence
        if features.user_features.get('has_profile', False):
            confidence_factors.append(0.85)
        else:
            confidence_factors.append(0.4)
        
        # Platform-specific confidence
        platform = features.platform_features.get('platform', 'instagram')
        if platform in self.platform_weights:
            confidence_factors.append(0.9)
        else:
            confidence_factors.append(0.6)
        
        return np.mean(confidence_factors)
    
    # Helper methods for feature extraction
    def _calculate_reading_complexity(self, text: str) -> float:
        """Calculate text reading complexity (Flesch-Kincaid grade level)"""
        if not text:
            return 0.0
        
        sentences = len(re.split(r'[.!?]+', text))
        words = len(text.split())
        syllables = sum(self._count_syllables(word) for word in text.split())
        
        if sentences == 0 or words == 0:
            return 0.0
        
        # Flesch-Kincaid Grade Level
        grade_level = 0.39 * (words / sentences) + 11.8 * (syllables / words) - 15.59
        return max(0.0, min(20.0, grade_level))
    
    def _count_syllables(self, word: str) -> int:
        """Count syllables in a word"""
        word = word.lower()
        vowels = 'aeiouy'
        syllable_count = 0
        previous_char_was_vowel = False
        
        for char in word:
            is_vowel = char in vowels
            if is_vowel and not previous_char_was_vowel:
                syllable_count += 1
            previous_char_was_vowel = is_vowel
        
        # Handle silent 'e'
        if word.endswith('e') and syllable_count > 1:
            syllable_count -= 1
        
        return max(1, syllable_count)
    
    def _analyze_image_colors(self, image: np.ndarray) -> Dict:
        """Analyze color composition of image"""
        # Convert to RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # Calculate color statistics
        mean_color = np.mean(image_rgb.reshape(-1, 3), axis=0)
        std_color = np.std(image_rgb.reshape(-1, 3), axis=0)
        
        # Color vibrancy (saturation)
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        saturation = np.mean(hsv[:, :, 1])
        
        return {
            'red_mean': float(mean_color[0]) / 255.0,
            'green_mean': float(mean_color[1]) / 255.0,
            'blue_mean': float(mean_color[2]) / 255.0,
            'color_variance': float(np.mean(std_color)) / 255.0,
            'saturation': float(saturation) / 255.0,
            'is_colorful': saturation > 100
        }
    
    def _detect_faces(self, image: np.ndarray) -> int:
        """Detect number of faces in image"""
        try:
            # Use OpenCV Haar cascade for face detection
            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, 1.1, 4)
            return len(faces)
        except:
            return 0
    
    def _detect_objects(self, image: np.ndarray) -> Dict:
        """Detect objects in image (simplified implementation)"""
        # In production, use YOLO or similar object detection model
        height, width = image.shape[:2]
        
        # Simplified object detection based on image properties
        features = {
            'has_people': self._detect_faces(image) > 0,
            'is_portrait': height > width,
            'is_landscape': width > height,
            'is_square': abs(height - width) < 50,
            'image_complexity': self._calculate_image_complexity(image)
        }
        
        return features
    
    def _calculate_image_complexity(self, image: np.ndarray) -> float:
        """Calculate image complexity based on edge density"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
        return float(edge_density)
    
    def _classify_audio_type(self, y: np.ndarray, sr: int) -> str:
        """Classify audio as music, speech, or mixed"""
        # Simplified classification based on audio features
        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y))
        
        # Simple heuristic classification
        if spectral_centroid > 3000 and zero_crossing_rate > 0.1:
            return 'music'
        elif spectral_centroid < 2000 and zero_crossing_rate < 0.05:
            return 'speech'
        else:
            return 'mixed'
    
    def _detect_call_to_action(self, text: str) -> bool:
        """Detect if text contains call-to-action phrases"""
        cta_phrases = [
            'click', 'subscribe', 'follow', 'like', 'share', 'comment',
            'check out', 'visit', 'download', 'sign up', 'join',
            'buy', 'shop', 'get', 'try', 'learn more', 'swipe up'
        ]
        
        text_lower = text.lower()
        return any(phrase in text_lower for phrase in cta_phrases)
    
    def _calculate_trending_score(self, content: Dict) -> float:
        """Calculate trending score based on hashtags and keywords"""
        # Simplified trending calculation
        text = content.get('text', '').lower()
        hashtags = re.findall(r'#\w+', text)
        
        # Mock trending hashtags (in production, fetch from real trending data)
        trending_hashtags = ['#viral', '#trending', '#fyp', '#foryou', '#reels', '#tiktok']
        trending_keywords = ['trending', 'viral', 'popular', 'hot', 'breaking']
        
        trending_score = 0.0
        
        # Score trending hashtags
        for hashtag in hashtags:
            if hashtag.lower() in trending_hashtags:
                trending_score += 0.2
        
        # Score trending keywords
        for keyword in trending_keywords:
            if keyword in text:
                trending_score += 0.1
        
        return min(1.0, trending_score)
    
    # Caching methods
    def _generate_cache_key(self, content: Dict, user_profile: Dict, platform: str) -> str:
        """Generate unique cache key for prediction"""
        content_hash = hashlib.md5(str(content).encode()).hexdigest()[:16]
        user_hash = hashlib.md5(str(user_profile).encode()).hexdigest()[:16]
        return f"engagement:{platform}:{content_hash}:{user_hash}"
    
    async def _get_cached_prediction(self, cache_key: str) -> Optional[EngagementPrediction]:
        """Get cached prediction if available"""
        if not self.redis_client:
            return self.feature_cache.get(cache_key)
        
        try:
            cached_data = self.redis_client.get(cache_key)
            if cached_data:
                data = json.loads(cached_data)
                return EngagementPrediction(**data)
        except Exception as e:
            logger.warning(f"Cache retrieval failed: {e}")
        
        return None
    
    async def _cache_prediction(self, cache_key: str, prediction: EngagementPrediction):
        """Cache prediction result"""
        try:
            data = {
                'engagement_score': prediction.engagement_score,
                'confidence': prediction.confidence,
                'platform_specific_scores': prediction.platform_specific_scores,
                'viral_probability': prediction.viral_probability,
                'quality_multiplier': prediction.quality_multiplier,
                'xp_multiplier': prediction.xp_multiplier,
                'breakdown': prediction.breakdown,
                'recommendations': prediction.recommendations
            }
            
            if self.redis_client:
                self.redis_client.setex(
                    cache_key, 
                    self.config['prediction_cache_ttl'], 
                    json.dumps(data)
                )
            else:
                self.feature_cache[cache_key] = prediction
                
        except Exception as e:
            logger.warning(f"Cache storage failed: {e}")
    
    # Model training methods (for future model updates)
    async def train_model(self, training_data: List[Dict], model_type: str = 'engagement'):
        """Train or update model with new data"""
        logger.info(f"Training {model_type} model with {len(training_data)} samples")
        
        # Prepare training data
        X, y = self._prepare_training_data(training_data)
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Train model based on type
        if model_type == 'engagement':
            model = self._create_engagement_model()
            # Training logic for neural network
            self._train_neural_network(model, X_train, y_train, X_test, y_test)
        else:
            model = self.models.get(model_type, RandomForestRegressor())
            model.fit(X_train, y_train)
            
            # Evaluate
            y_pred = model.predict(X_test)
            mse = mean_squared_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            logger.info(f"Model {model_type} - MSE: {mse:.4f}, R2: {r2:.4f}")
        
        # Update model
        self.models[model_type] = model
        
        # Save model
        await self._save_model(model, model_type)
    
    def _prepare_training_data(self, training_data: List[Dict]) -> Tuple[np.ndarray, np.ndarray]:
        """Prepare training data for model"""
        X, y = [], []
        
        for sample in training_data:
            # Extract features
            features = asyncio.run(self._extract_features(
                sample['content'], 
                sample.get('user_profile'), 
                sample.get('platform', 'instagram')
            ))
            
            # Convert to feature vector
            feature_vector = self._combine_features(features)
            X.append(feature_vector)
            y.append(sample['engagement_score'])
        
        return np.array(X), np.array(y)
    
    def _train_neural_network(self, model: nn.Module, X_train: np.ndarray, y_train: np.ndarray, 
                            X_test: np.ndarray, y_test: np.ndarray):
        """Train neural network model"""
        # Convert to tensors
        X_train_tensor = torch.FloatTensor(X_train)
        y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)
        X_test_tensor = torch.FloatTensor(X_test)
        y_test_tensor = torch.FloatTensor(y_test).unsqueeze(1)
        
        # Training setup
        criterion = nn.MSELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
        # Training loop
        epochs = 100
        for epoch in range(epochs):
            model.train()
            optimizer.zero_grad()
            
            outputs = model(X_train_tensor)
            loss = criterion(outputs, y_train_tensor)
            loss.backward()
            optimizer.step()
            
            if epoch % 20 == 0:
                model.eval()
                with torch.no_grad():
                    test_outputs = model(X_test_tensor)
                    test_loss = criterion(test_outputs, y_test_tensor)
                    logger.info(f"Epoch {epoch}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}")
    
    async def _save_model(self, model, model_type: str):
        """Save trained model"""
        try:
            model_path = f"models/{model_type}_model.pkl"
            with open(model_path, 'wb') as f:
                pickle.dump(model, f)
            logger.info(f"Model {model_type} saved to {model_path}")
        except Exception as e:
            logger.error(f"Failed to save model {model_type}: {e}")


class EngagementNN(nn.Module):
    """Neural Network for engagement prediction"""
    
    def __init__(self, input_dim: int, hidden_dims: List[int], output_dim: int, dropout: float = 0.3):
        super(EngagementNN, self).__init__()
        
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(prev_dim, hidden_dim))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(dropout))
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, output_dim))
        layers.append(nn.Sigmoid())  # Output between 0 and 1
        
        self.network = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.network(x) * 10.0  # Scale to 0-10 range


# Utility functions for integration with Finova ecosystem
class FinovaIntegration:
    """Integration utilities for Finova Network ecosystem"""
    
    @staticmethod
    def calculate_fin_mining_boost(engagement_prediction: EngagementPrediction) -> float:
        """Calculate FIN mining boost based on engagement prediction"""
        base_boost = engagement_prediction.engagement_score / 10.0
        quality_boost = (engagement_prediction.quality_multiplier - 1.0) * 0.5
        viral_boost = engagement_prediction.viral_probability * 0.3
        
        total_boost = base_boost + quality_boost + viral_boost
        return min(2.0, max(0.1, total_boost))  # Cap between 0.1x and 2.0x
    
    @staticmethod
    def calculate_xp_multiplier(engagement_prediction: EngagementPrediction) -> float:
        """Calculate XP multiplier for Finova XP system"""
        return engagement_prediction.xp_multiplier
    
    @staticmethod
    def should_trigger_viral_bonus(engagement_prediction: EngagementPrediction) -> bool:
        """Determine if content should trigger viral bonus"""
        return (engagement_prediction.viral_probability > 0.7 and 
                engagement_prediction.engagement_score > 5.0)
    
    @staticmethod
    def generate_finova_metrics(engagement_prediction: EngagementPrediction) -> Dict:
        """Generate Finova-specific metrics"""
        return {
            'fin_mining_boost': FinovaIntegration.calculate_fin_mining_boost(engagement_prediction),
            'xp_multiplier': engagement_prediction.xp_multiplier,
            'rp_network_bonus': engagement_prediction.viral_probability * 0.2,
            'quality_tier': 'high' if engagement_prediction.quality_multiplier > 1.5 else 
                           'medium' if engagement_prediction.quality_multiplier > 1.0 else 'low',
            'viral_eligible': FinovaIntegration.should_trigger_viral_bonus(engagement_prediction),
            'platform_optimization': max(engagement_prediction.platform_specific_scores.items(), 
                                       key=lambda x: x[1])
        }


# Example usage and testing
async def main():
    """Example usage of the EngagementPredictor"""
    
    # Initialize predictor
    predictor = EngagementPredictor()
    
    # Example content
    content = {
        'text': 'Amazing sunset today! ðŸŒ… #sunset #photography #nature #beautiful',
        'images': ['sunset_image.jpg'],
        'type': 'post',
        'title': 'Beautiful Sunset',
        'tags': ['sunset', 'photography', 'nature']
    }
    
    # Example user profile
    user_profile = {
        'follower_count': 1500,
        'following_count': 800,
        'post_count': 250,
        'account_age_days': 365,
        'avg_engagement_rate': 0.05,
        'xp_level': 25,
        'rp_tier': 2,
        'current_mining_rate': 0.05,
        'avg_quality_score': 0.75
    }
    
    # Predict engagement
    prediction = await predictor.predict_engagement(content, user_profile, 'instagram')
    
    # Display results
    print(f"Engagement Score: {prediction.engagement_score:.2f}")
    print(f"Confidence: {prediction.confidence:.2f}")
    print(f"Viral Probability: {prediction.viral_probability:.2f}")
    print(f"Quality Multiplier: {prediction.quality_multiplier:.2f}")
    print(f"XP Multiplier: {prediction.xp_multiplier:.2f}")
    print(f"Platform Scores: {prediction.platform_specific_scores}")
    print(f"Recommendations: {prediction.recommendations}")
    
    # Generate Finova-specific metrics
    finova_metrics = FinovaIntegration.generate_finova_metrics(prediction)
    print(f"Finova Metrics: {finova_metrics}")


if __name__ == "__main__":
    asyncio.run(main())
    